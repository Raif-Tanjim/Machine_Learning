{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0033DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0068DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0078DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0153DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0166DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0174DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0197DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0215DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0221DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0264DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0296DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0301DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0314DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0318DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0366DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0434DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0452DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0454DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0513DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0515DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0522DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0527DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0531DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0532DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0534DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0536DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0539DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0540DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0541DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0543DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0544DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0545DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0546DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0550DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0551DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0554DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0555DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0560DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0562DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0569DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0575DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0578DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0580DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0583DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0585DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0592DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0595DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0600DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0608DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0134DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0187DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0228DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0308DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0372DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0411DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0030DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0557DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0561DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0565DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0570DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0576DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0579DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0582DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0584DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0591DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0594DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0597DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0601DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v2/s0610DB-v2\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0215DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0221DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0228DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0264DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0301DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0318DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0372DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0434DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0452DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0527DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0534DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0536DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0540DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0543DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0544DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0546DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0550DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0551DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0560DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0561DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0565DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0575DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0578DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0579DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0582DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0583DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0594DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0366DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0454DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0539DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0545DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0555DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0570DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0580DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0610DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0030DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0068DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0134DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0174DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0187DB-v8\n",
      "Generating record list for: ./Data/Labview/Converted/Labview-v8/s0197DB-v8\n",
      "Generating record list for: ./Data/ECG/S0033ECG\n",
      "Generating record list for: ./Data/ECG/S0064ECG\n",
      "Generating record list for: ./Data/ECG/S0068ECG\n",
      "Generating record list for: ./Data/ECG/S0105ECG\n",
      "Generating record list for: ./Data/ECG/S0134ECG\n",
      "Generating record list for: ./Data/ECG/S0153ECG\n",
      "Generating record list for: ./Data/ECG/S0166ECG\n",
      "Generating record list for: ./Data/ECG/S0173ECG\n",
      "Generating record list for: ./Data/ECG/S0174ECG\n",
      "Generating record list for: ./Data/ECG/S0197ECG\n",
      "Generating record list for: ./Data/ECG/S0215ECG\n",
      "Generating record list for: ./Data/ECG/S0228ECG\n",
      "Generating record list for: ./Data/ECG/S0233ECG\n",
      "Generating record list for: ./Data/ECG/S0264ECG\n",
      "Generating record list for: ./Data/ECG/S0296ECG\n",
      "Generating record list for: ./Data/ECG/S0301ECG\n",
      "Generating record list for: ./Data/ECG/S0308ECG\n",
      "Generating record list for: ./Data/ECG/S0314ECG\n",
      "Generating record list for: ./Data/ECG/S0318ECG\n",
      "Generating record list for: ./Data/ECG/S0327ECG\n",
      "Generating record list for: ./Data/ECG/S0366ECG\n",
      "Generating record list for: ./Data/ECG/S0372ECG\n",
      "Generating record list for: ./Data/ECG/S0411ECG\n",
      "Generating record list for: ./Data/ECG/S0430ECG\n",
      "Generating record list for: ./Data/ECG/S0452ECG\n",
      "Generating record list for: ./Data/ECG/S0454ECG\n",
      "Generating record list for: ./Data/ECG/S0513ECG\n",
      "Generating record list for: ./Data/ECG/S0516ECG\n",
      "Generating record list for: ./Data/ECG/S0536ECG\n",
      "Generating record list for: ./Data/ECG/S0539ECG\n",
      "Generating record list for: ./Data/ECG/S0540ECG\n",
      "Generating record list for: ./Data/ECG/S0541ECG\n",
      "Generating record list for: ./Data/ECG/S0543ECG\n",
      "Generating record list for: ./Data/ECG/S0546ECG\n",
      "Generating record list for: ./Data/ECG/S0548ECG\n",
      "Generating record list for: ./Data/ECG/S0552ECG\n",
      "Generating record list for: ./Data/ECG/S0554ECG\n",
      "Generating record list for: ./Data/ECG/S0555ECG\n",
      "Generating record list for: ./Data/ECG/S0561ECG\n",
      "Generating record list for: ./Data/ECG/S0562ECG\n",
      "Generating record list for: ./Data/ECG/S0576ECG\n",
      "Generating record list for: ./Data/ECG/S0578ECG\n",
      "Generating record list for: ./Data/ECG/S0582ECG\n",
      "Generating record list for: ./Data/ECG/S0585ECG\n",
      "Generating record list for: ./Data/ECG/S0591ECG\n",
      "Generating record list for: ./Data/ECG/S0600ECG\n",
      "Generating record list for: ./Data/ECG/S0610ECG\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0033DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0068DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0078DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0153DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0166DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0174DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0197DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0215DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0221DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0264DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0296DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0301DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0314DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0318DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0366DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0434DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0452DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0454DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0513DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0515DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0522DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0527DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0531DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0532DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0534DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0536DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0539DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0540DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0541DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0543DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0544DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0545DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0546DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0550DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0551DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0554DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0555DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0560DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0562DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0569DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0575DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0578DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0580DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0583DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0585DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0592DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0595DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0600DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0608DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0134DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0187DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0228DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0308DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0372DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0411DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0030DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0557DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0561DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0565DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0570DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0576DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0579DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0582DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0584DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0591DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0594DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0597DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0601DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v2/s0610DB-v2\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0215DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0221DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0228DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0264DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0301DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0318DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0372DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0434DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0452DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0527DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0534DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0536DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0540DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0543DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0544DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0546DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0550DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0551DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0560DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0561DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0565DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0575DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0578DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0579DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0582DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0583DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0594DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0366DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0454DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0539DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0545DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0555DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0570DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0580DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0610DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0030DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0068DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0134DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0174DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0187DB-v8\n",
      "Generating list of all files for: ./Data/Labview/Converted/Labview-v8/s0197DB-v8\n",
      "Generating list of all files for: ./Data/ECG/S0033ECG\n",
      "Generating list of all files for: ./Data/ECG/S0064ECG\n",
      "Generating list of all files for: ./Data/ECG/S0068ECG\n",
      "Generating list of all files for: ./Data/ECG/S0105ECG\n",
      "Generating list of all files for: ./Data/ECG/S0134ECG\n",
      "Generating list of all files for: ./Data/ECG/S0153ECG\n",
      "Generating list of all files for: ./Data/ECG/S0166ECG\n",
      "Generating list of all files for: ./Data/ECG/S0173ECG\n",
      "Generating list of all files for: ./Data/ECG/S0174ECG\n",
      "Generating list of all files for: ./Data/ECG/S0197ECG\n",
      "Generating list of all files for: ./Data/ECG/S0215ECG\n",
      "Generating list of all files for: ./Data/ECG/S0228ECG\n",
      "Generating list of all files for: ./Data/ECG/S0233ECG\n",
      "Generating list of all files for: ./Data/ECG/S0264ECG\n",
      "Generating list of all files for: ./Data/ECG/S0296ECG\n",
      "Generating list of all files for: ./Data/ECG/S0301ECG\n",
      "Generating list of all files for: ./Data/ECG/S0308ECG\n",
      "Generating list of all files for: ./Data/ECG/S0314ECG\n",
      "Generating list of all files for: ./Data/ECG/S0318ECG\n",
      "Generating list of all files for: ./Data/ECG/S0327ECG\n",
      "Generating list of all files for: ./Data/ECG/S0366ECG\n",
      "Generating list of all files for: ./Data/ECG/S0372ECG\n",
      "Generating list of all files for: ./Data/ECG/S0411ECG\n",
      "Generating list of all files for: ./Data/ECG/S0430ECG\n",
      "Generating list of all files for: ./Data/ECG/S0452ECG\n",
      "Generating list of all files for: ./Data/ECG/S0454ECG\n",
      "Generating list of all files for: ./Data/ECG/S0513ECG\n",
      "Generating list of all files for: ./Data/ECG/S0516ECG\n",
      "Generating list of all files for: ./Data/ECG/S0536ECG\n",
      "Generating list of all files for: ./Data/ECG/S0539ECG\n",
      "Generating list of all files for: ./Data/ECG/S0540ECG\n",
      "Generating list of all files for: ./Data/ECG/S0541ECG\n",
      "Generating list of all files for: ./Data/ECG/S0543ECG\n",
      "Generating list of all files for: ./Data/ECG/S0546ECG\n",
      "Generating list of all files for: ./Data/ECG/S0548ECG\n",
      "Generating list of all files for: ./Data/ECG/S0552ECG\n",
      "Generating list of all files for: ./Data/ECG/S0554ECG\n",
      "Generating list of all files for: ./Data/ECG/S0555ECG\n",
      "Generating list of all files for: ./Data/ECG/S0561ECG\n",
      "Generating list of all files for: ./Data/ECG/S0562ECG\n",
      "Generating list of all files for: ./Data/ECG/S0576ECG\n",
      "Generating list of all files for: ./Data/ECG/S0578ECG\n",
      "Generating list of all files for: ./Data/ECG/S0582ECG\n",
      "Generating list of all files for: ./Data/ECG/S0585ECG\n",
      "Generating list of all files for: ./Data/ECG/S0591ECG\n",
      "Generating list of all files for: ./Data/ECG/S0600ECG\n",
      "Generating list of all files for: ./Data/ECG/S0610ECG\n",
      "Created local base download directory: ./cded\n",
      "Downloading files...\n",
      "Finished downloading files\n"
     ]
    }
   ],
   "source": [
    "# import wfdb\n",
    "\n",
    "# # This will download and extract CDED dataset to './cded'\n",
    "# wfdb.dl_database('cded', dl_dir='./cded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographics shape: (121, 254)\n",
      "Labs shape: (121, 170)\n",
      "History shape: (121, 174)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "base_path = r'C:/Users/r/Machine_Learning/HRV Early cardiac risk detection/cded/DATA_discription/'\n",
    "\n",
    "demographics_path = os.path.join(base_path, 'GE-79_Summary_Table-Demographics-MRI-Part1.csv')\n",
    "labs_path = os.path.join(base_path, 'GE-79_Summary_Table-Labs-BP-Ophthalmogic-Walk.csv')\n",
    "history_path = os.path.join(base_path, 'GE-79_Summary_Table-MRI-Part5-History.csv')\n",
    "\n",
    "demographics = pd.read_csv(demographics_path, encoding='latin1')\n",
    "labs_bp = pd.read_csv(labs_path, encoding='latin1')\n",
    "history = pd.read_csv(history_path, encoding='latin1')\n",
    "\n",
    "print(\"Demographics shape:\", demographics.shape)\n",
    "print(\"Labs shape:\", labs_bp.shape)\n",
    "print(\"History shape:\", history.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics.rename(columns={'Patient ID': 'patient_id', 'Visit': 'visit'}, inplace=True)\n",
    "labs_bp.rename(columns={'patient ID': 'patient_id', 'Visit': 'visit'}, inplace=True)\n",
    "history.rename(columns={'Patient ID': 'patient_id', 'Visit': 'visit'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['patient ID', 'visit',\n",
      "       'Perfusion Vascular (Lepto MCA) -  baseline 1 Right - 6 min',\n",
      "       'Perfusion Vascular (Lepto PCA) -  baseline 1 Right - 6 min',\n",
      "       'Perfusion Vascular (MCA Perf) - baseline 1 Right - 6 min',\n",
      "       'Perfusion Vascular (POCA) - baseline 1 Right - 6 min',\n",
      "       'Perfusion Vascular (whole brain) - baseline 1 whole - 6 min',\n",
      "       'Perfusion Vascular (ACA Perf) -  baseline 1 whole - 6 min',\n",
      "       'Perfusion Vascular (ACHA) -  baseline 1 whole - 6 min',\n",
      "       'Perfusion Vascular (Lepto ACA) -  baseline 1 whole - 6 min',\n",
      "       ...\n",
      "       'STATINS', 'ESTROGEN', 'ACE INHIBITORS', 'ARBS', 'BETA BLOCKERS',\n",
      "       'DIURETICS', 'CA ++ BLOCKERS', 'INSULIN(Yes_or_No)',\n",
      "       'ORAL HYPOGLYCEMIC', 'OTHER 2'],\n",
      "      dtype='object', length=174)\n"
     ]
    }
   ],
   "source": [
    "print(history.columns)\n",
    "history.rename(columns={'patient ID': 'patient_id', 'visit': 'visit'}, inplace=True)\n",
    "df = pd.merge(df, history, on=['patient_id', 'visit'], how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset shape: (121, 594)\n",
      "  patient_id  visit\n",
      "0      S0030      2\n",
      "1      S0033      2\n",
      "2      S0064      2\n",
      "3      S0068      2\n",
      "4      S0078      2\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(demographics, labs_bp, on=['patient_id', 'visit'], how='inner')\n",
    "df = pd.merge(df, history, on=['patient_id', 'visit'], how='left')\n",
    "\n",
    "print(\"Merged dataset shape:\", df.shape)\n",
    "print(df[['patient_id', 'visit']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Non-DM' 'DM']\n",
      "['ntn' 'HTN' nan]\n",
      "  Dizziness AUTONOMIC SYMPTOMS_x Syncope AUTONOMIC SYMPTOMS_x  \\\n",
      "0                             NO                           NO   \n",
      "1                             NO                           NO   \n",
      "2                             NO                           NO   \n",
      "3                             NO                           NO   \n",
      "4                             NO                           NO   \n",
      "\n",
      "  OH AUTONOMIC SYMPTOMS_x  \n",
      "0                      NO  \n",
      "1                      NO  \n",
      "2                      NO  \n",
      "3                      NO  \n",
      "4                      NO  \n"
     ]
    }
   ],
   "source": [
    "print(df['DM, Non-DM, STROKE'].unique())\n",
    "print(df['HTN or not'].unique())\n",
    "\n",
    "autonomic_cols = [\n",
    "    'Dizziness AUTONOMIC SYMPTOMS_x',\n",
    "    'Syncope AUTONOMIC SYMPTOMS_x',\n",
    "    'OH AUTONOMIC SYMPTOMS_x'\n",
    "]\n",
    "print(df[autonomic_cols].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAN_risk_label\n",
      "0    66\n",
      "1    55\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def define_can_risk(row):\n",
    "    has_diabetes = row['DM, Non-DM, STROKE'] == 'DM'\n",
    "    has_htn = row['HTN or not'] == 'HTN'\n",
    "\n",
    "    autonomic_cols = [\n",
    "        'Dizziness AUTONOMIC SYMPTOMS_x',\n",
    "        'Syncope AUTONOMIC SYMPTOMS_x',\n",
    "        'OH AUTONOMIC SYMPTOMS_x'\n",
    "    ]\n",
    "    \n",
    "    has_autonomic = any(\n",
    "        str(row.get(col)).strip().upper() == 'YES'\n",
    "        for col in autonomic_cols if col in row and pd.notna(row[col])\n",
    "    )\n",
    "\n",
    "    if has_diabetes and (has_autonomic or has_htn):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the function\n",
    "df['CAN_risk_label'] = df.apply(define_can_risk, axis=1)\n",
    "\n",
    "# Check results\n",
    "print(df['CAN_risk_label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dizziness AUTONOMIC SYMPTOMS_x unique values: ['NO' 'Yes' 'YES']\n",
      "Syncope AUTONOMIC SYMPTOMS_x unique values: ['NO' 'YES' nan]\n",
      "OH AUTONOMIC SYMPTOMS_x unique values: ['NO' 'YES']\n"
     ]
    }
   ],
   "source": [
    "for col in ['Dizziness AUTONOMIC SYMPTOMS_x', 'Syncope AUTONOMIC SYMPTOMS_x', 'OH AUTONOMIC SYMPTOMS_x']:\n",
    "    print(f\"{col} unique values:\", df[col].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (121, 505)\n",
      "   Diabetes Duration  HEIGHT (M)  MASS (KG)        BMI  global GM vol  \\\n",
      "0                NaN        1.62       69.4  26.444140         661.50   \n",
      "1                NaN        1.80       97.0  29.938272         583.40   \n",
      "2                NaN        1.70       70.9  24.532872         655.58   \n",
      "3                NaN        1.55       70.8  29.469303         493.01   \n",
      "4                NaN        1.54       44.0  18.552876         473.03   \n",
      "\n",
      "   global GM vol covered in template  L superior frontal gyrus (#21) GM  \\\n",
      "0                             661.03                             28.856   \n",
      "1                             582.94                             25.006   \n",
      "2                             655.06                             29.075   \n",
      "3                             491.81                             18.922   \n",
      "4                             472.70                             19.539   \n",
      "\n",
      "   R superior frontal gyrus (#22) GM  L middle frontal gyrus (#23) GM  \\\n",
      "0                             29.288                           23.023   \n",
      "1                             26.599                           19.565   \n",
      "2                             29.052                           23.365   \n",
      "3                             19.375                           16.364   \n",
      "4                             19.618                           16.179   \n",
      "\n",
      "   R middle frontal gyrus (#24) GM  ...  Symptoms 2_y  Lesions 2_y  \\\n",
      "0                           24.084  ...           NaN          NaN   \n",
      "1                           21.393  ...           NaN          NaN   \n",
      "2                           24.352  ...           NaN          NaN   \n",
      "3                           16.519  ...           NaN          NaN   \n",
      "4                           16.074  ...           NaN          NaN   \n",
      "\n",
      "   Carotids_y  Visit 2 date_y  2nd Stroke 2_y  medication_old_y  \\\n",
      "0         NaN             NaN             NaN               NaN   \n",
      "1         NaN             NaN             NaN               NaN   \n",
      "2         NaN             NaN             NaN               NaN   \n",
      "3         NaN             NaN             NaN               NaN   \n",
      "4         NaN             NaN             NaN               NaN   \n",
      "\n",
      "   Diabetic Medication Taken_y  Meds for HTN Tapered_y  \\\n",
      "0                          NaN                     NaN   \n",
      "1                          NaN                     NaN   \n",
      "2                          NaN                     NaN   \n",
      "3                          NaN                     NaN   \n",
      "4                          NaN                     NaN   \n",
      "\n",
      "   Class of Meds Tapered_y  Tapered Medications taken during Visit 2_y  \n",
      "0                      NaN                                         NaN  \n",
      "1                      NaN                                         NaN  \n",
      "2                      NaN                                         NaN  \n",
      "3                      NaN                                         NaN  \n",
      "4                      NaN                                         NaN  \n",
      "\n",
      "[5 rows x 505 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop identifiers and irrelevant columns\n",
    "features_to_drop = ['patient_id', 'visit', 'DM, Non-DM, STROKE', 'HTN or not', \n",
    "                    'Dizziness AUTONOMIC SYMPTOMS_x', 'Syncope AUTONOMIC SYMPTOMS_x', \n",
    "                    'OH AUTONOMIC SYMPTOMS_x']\n",
    "\n",
    "# Keep only numeric features and drop columns we don't need\n",
    "X = df.drop(columns=features_to_drop + ['CAN_risk_label']).select_dtypes(include=[np.number])\n",
    "\n",
    "# Target variable\n",
    "y = df['CAN_risk_label']\n",
    "\n",
    "print(\"Feature shape:\", X.shape)\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  1]\n",
      " [ 2 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93        20\n",
      "           1       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.92        37\n",
      "   macro avg       0.92      0.92      0.92        37\n",
      "weighted avg       0.92      0.92      0.92        37\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\r\\Machine_Learning\\HRV Early cardiac risk detection\\.venv\\lib\\site-packages\\sklearn\\utils\\extmath.py:1144: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Users\\r\\Machine_Learning\\HRV Early cardiac risk detection\\.venv\\lib\\site-packages\\sklearn\\utils\\extmath.py:1149: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "c:\\Users\\r\\Machine_Learning\\HRV Early cardiac risk detection\\.venv\\lib\\site-packages\\sklearn\\utils\\extmath.py:1169: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (595176, 8)\n",
      "Sampling frequency: 1000 Hz\n"
     ]
    }
   ],
   "source": [
    "import wfdb\n",
    "\n",
    "# Example ECG record name (adjust based on your files)\n",
    "record_name = 'S0033ECG'  # change to your actual record name\n",
    "\n",
    "# Path to ECG record folder\n",
    "ecg_folder = r'C:/Users/r/Machine_Learning/HRV Early cardiac risk detection/cded/Data/ECG/'  # adjust path\n",
    "\n",
    "# Read the record\n",
    "record = wfdb.rdrecord(f'{ecg_folder}/{record_name}')\n",
    "\n",
    "# Access ECG signal data (multi-channel if available)\n",
    "ecg_signal = record.p_signal  # numpy array, shape=(n_samples, n_channels)\n",
    "\n",
    "print(f\"Signal shape: {ecg_signal.shape}\")\n",
    "print(f\"Sampling frequency: {record.fs} Hz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   HRV_MeanNN   HRV_SDNN  HRV_SDANN1  HRV_SDNNI1  HRV_SDANN2  HRV_SDNNI2  \\\n",
      "0  879.029586  76.276373   76.742899   26.111553   69.216742   39.507039   \n",
      "\n",
      "   HRV_SDANN5  HRV_SDNNI5  HRV_RMSSD   HRV_SDSD  ...  HRV_IQRNN  HRV_SDRMSSD  \\\n",
      "0         NaN         NaN  20.713638  20.728922  ...     109.75     3.682423   \n",
      "\n",
      "   HRV_Prc20NN  HRV_Prc80NN  HRV_pNN50  HRV_pNN20  HRV_MinNN  HRV_MaxNN  \\\n",
      "0        821.0        961.0    1.47929  17.307692      766.0     1084.0   \n",
      "\n",
      "    HRV_HTI  HRV_TINN  \n",
      "0  8.894737  101.5625  \n",
      "\n",
      "[1 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import neurokit2 as nk\n",
    "\n",
    "# Example: Take first channel ECG data\n",
    "ecg_ch1 = ecg_signal[:, 0]\n",
    "\n",
    "# Detect R-peaks\n",
    "signals, info = nk.ecg_process(ecg_ch1, sampling_rate=record.fs)\n",
    "\n",
    "# Extract HRV features\n",
    "hrv_features = nk.hrv_time(signals[\"ECG_R_Peaks\"], sampling_rate=record.fs)\n",
    "print(hrv_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   HRV_MeanNN    HRV_SDNN  HRV_SDANN1  HRV_SDNNI1  HRV_SDANN2  HRV_SDNNI2  \\\n",
      "0  879.029586   76.276373   76.742899   26.111553   69.216742   39.507039   \n",
      "1  982.590571  123.302236   84.304607   89.460749   64.294791   88.414396   \n",
      "2  685.945355   53.959304   59.012233   19.816811   49.785432   32.498280   \n",
      "3  758.582359  228.805327  196.530270   94.513943  139.704868  130.124056   \n",
      "4  759.156627  293.123764   96.469767  264.880697  101.417513  265.055038   \n",
      "\n",
      "   HRV_SDANN5  HRV_SDNNI5   HRV_RMSSD    HRV_SDSD  ...  HRV_Prc20NN  \\\n",
      "0         NaN         NaN   20.713638   20.728922  ...        821.0   \n",
      "1         NaN         NaN   65.333454   65.414853  ...        956.0   \n",
      "2         NaN         NaN   14.399222   14.406518  ...        651.0   \n",
      "3         NaN         NaN  133.358894  133.361227  ...        631.0   \n",
      "4         NaN         NaN  391.413609  391.807815  ...        583.8   \n",
      "\n",
      "   HRV_Prc80NN  HRV_pNN50  HRV_pNN20  HRV_MinNN  HRV_MaxNN    HRV_HTI  \\\n",
      "0        961.0   1.479290  17.307692      766.0     1084.0   8.894737   \n",
      "1       1031.2  11.414392  38.213400      423.0     1304.0  11.194444   \n",
      "2        705.0   1.275046   8.561020      601.0      918.0   6.238636   \n",
      "3        914.0  10.095643  27.948990      553.0     4865.0  14.476923   \n",
      "4        863.2  73.493976  81.325301      314.0     3095.0  17.785714   \n",
      "\n",
      "   HRV_TINN  patient_id  visit  \n",
      "0  101.5625       S0033      2  \n",
      "1    0.0000       S0064      2  \n",
      "2  101.5625       S0068      2  \n",
      "3  132.8125       S0105      2  \n",
      "4  437.5000       S0134      2  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import neurokit2 as nk\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "import os\n",
    "\n",
    "ecg_folder = r'C:/Users/r/Machine_Learning/HRV Early cardiac risk detection/cded/Data/ECG/'\n",
    "\n",
    "hrv_list = []\n",
    "\n",
    "for record_path in glob.glob(os.path.join(ecg_folder, '*ECG.hea')):\n",
    "    record_name = os.path.splitext(os.path.basename(record_path))[0].replace('.hea','')\n",
    "    try:\n",
    "        record = wfdb.rdrecord(os.path.join(ecg_folder, record_name))\n",
    "        ecg_signal = record.p_signal[:, 0]  # pick first channel\n",
    "        signals, info = nk.ecg_process(ecg_signal, sampling_rate=record.fs)\n",
    "        hrv = nk.hrv_time(signals[\"ECG_R_Peaks\"], sampling_rate=record.fs)\n",
    "        hrv['patient_id'] = record_name[:5]  # adjust slicing based on your naming\n",
    "        hrv['visit'] = 2  # or extract from metadata if available\n",
    "        hrv_list.append(hrv)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed {record_name}: {e}\")\n",
    "\n",
    "df_hrv = pd.concat(hrv_list, ignore_index=True)\n",
    "print(df_hrv.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (42, 620)\n"
     ]
    }
   ],
   "source": [
    "df_full = pd.merge(df, df_hrv, on=['patient_id', 'visit'], how='inner')\n",
    "\n",
    "print(\"Final dataset shape:\", df_full.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (42, 530)\n",
      "Target distribution:\n",
      "CAN_risk_label\n",
      "0    23\n",
      "1    19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define columns to drop (non-numeric or identifiers)\n",
    "features_to_drop = ['patient_id', 'visit', 'DM, Non-DM, STROKE', 'HTN or not', \n",
    "                    'Dizziness AUTONOMIC SYMPTOMS_x', 'Syncope AUTONOMIC SYMPTOMS_x', \n",
    "                    'OH AUTONOMIC SYMPTOMS_x', 'CAN_risk_label']\n",
    "\n",
    "# Select numeric features only\n",
    "X = df_full.drop(columns=features_to_drop).select_dtypes(include=[np.number])\n",
    "\n",
    "# Target variable\n",
    "y = df_full['CAN_risk_label']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original clinical data patient count: 77\n",
      "HRV feature patient count: 47\n",
      "Merged dataset patient count: 42\n"
     ]
    }
   ],
   "source": [
    "print(\"Original clinical data patient count:\", df['patient_id'].nunique())\n",
    "print(\"HRV feature patient count:\", df_hrv['patient_id'].nunique())\n",
    "print(\"Merged dataset patient count:\", df_full['patient_id'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset shape: (121, 620)\n",
      "Missing HRV feature rows: 79 out of 121\n",
      "After imputation, missing values per column:\n",
      "HRV_MeanNN      0\n",
      "HRV_SDNN        0\n",
      "HRV_SDANN1      0\n",
      "HRV_SDNNI1      0\n",
      "HRV_SDANN2      0\n",
      "HRV_SDNNI2      0\n",
      "HRV_SDANN5      0\n",
      "HRV_SDNNI5      0\n",
      "HRV_RMSSD       0\n",
      "HRV_SDSD        0\n",
      "HRV_CVNN        0\n",
      "HRV_CVSD        0\n",
      "HRV_MedianNN    0\n",
      "HRV_MadNN       0\n",
      "HRV_MCVNN       0\n",
      "HRV_IQRNN       0\n",
      "HRV_SDRMSSD     0\n",
      "HRV_Prc20NN     0\n",
      "HRV_Prc80NN     0\n",
      "HRV_pNN50       0\n",
      "HRV_pNN20       0\n",
      "HRV_MinNN       0\n",
      "HRV_MaxNN       0\n",
      "HRV_HTI         0\n",
      "HRV_TINN        0\n",
      "dtype: int64\n",
      "Final feature shape: (121, 531)\n",
      "Target distribution:\n",
      " CAN_risk_label\n",
      "0    66\n",
      "1    55\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\r\\AppData\\Local\\Temp\\ipykernel_6612\\1325462723.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_full[col].fillna(median_val, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Left merge clinical data (df) with HRV features (df_hrv)\n",
    "df_full = pd.merge(df, df_hrv, on=['patient_id', 'visit'], how='left')\n",
    "\n",
    "print(\"Merged dataset shape:\", df_full.shape)\n",
    "\n",
    "# Check how many missing HRV feature rows you have\n",
    "missing_hrv_count = df_full['HRV_MeanNN'].isna().sum()  # example HRV feature column\n",
    "print(f\"Missing HRV feature rows: {missing_hrv_count} out of {df_full.shape[0]}\")\n",
    "\n",
    "# Add a flag indicating if HRV data is available for each row\n",
    "df_full['hrv_available'] = df_full['HRV_MeanNN'].notna().astype(int)\n",
    "\n",
    "# Fill missing HRV features with median values\n",
    "hrv_columns = df_hrv.columns.drop(['patient_id', 'visit'])\n",
    "\n",
    "for col in hrv_columns:\n",
    "    median_val = df_full[col].median()\n",
    "    df_full[col].fillna(median_val, inplace=True)\n",
    "\n",
    "print(\"After imputation, missing values per column:\")\n",
    "print(df_full[hrv_columns].isna().sum())\n",
    "\n",
    "# Now you can prepare features and target for modeling\n",
    "features_to_drop = ['patient_id', 'visit', 'DM, Non-DM, STROKE', 'HTN or not', \n",
    "                    'Dizziness AUTONOMIC SYMPTOMS_x', 'Syncope AUTONOMIC SYMPTOMS_x', \n",
    "                    'OH AUTONOMIC SYMPTOMS_x', 'CAN_risk_label']  # plus others if needed\n",
    "\n",
    "X = df_full.drop(columns=features_to_drop).select_dtypes(include=[np.number])\n",
    "y = df_full['CAN_risk_label']\n",
    "\n",
    "print(\"Final feature shape:\", X.shape)\n",
    "print(\"Target distribution:\\n\", y.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running CV for Random Forest...\n",
      "Random Forest CV accuracy scores: [0.92       0.79166667 0.875      0.91666667 0.79166667]\n",
      "Random Forest Mean accuracy: 0.8590 (+/- 0.0572)\n",
      "\n",
      "Running CV for Logistic Regression...\n",
      "Logistic Regression CV accuracy scores: [0.84       0.75       0.83333333 0.75       0.70833333]\n",
      "Logistic Regression Mean accuracy: 0.7763 (+/- 0.0516)\n",
      "\n",
      "Running CV for XGBoost...\n",
      "XGBoost CV accuracy scores: [0.88       0.875      0.875      1.         0.95833333]\n",
      "XGBoost Mean accuracy: 0.9177 (+/- 0.0519)\n",
      "\n",
      "Running CV for KNN...\n",
      "KNN CV accuracy scores: [0.6        0.58333333 0.54166667 0.54166667 0.66666667]\n",
      "KNN Mean accuracy: 0.5867 (+/- 0.0461)\n",
      "\n",
      "Running CV for SVM...\n",
      "SVM CV accuracy scores: [0.8        0.75       0.58333333 0.625      0.75      ]\n",
      "SVM Mean accuracy: 0.7017 (+/- 0.0827)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'SVM': SVC(kernel='rbf', probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Running CV for {name}...\")\n",
    "    pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    scores = cross_val_score(pipe, X, y, cv=skf, scoring='accuracy', n_jobs=-1)\n",
    "    results[name] = scores\n",
    "    print(f\"{name} CV accuracy scores: {scores}\")\n",
    "    print(f\"{name} Mean accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best parameters found:\n",
      "{'subsample': np.float64(0.8), 'reg_lambda': 2, 'reg_alpha': 0.1, 'n_estimators': np.int64(100), 'max_depth': np.int64(4), 'learning_rate': np.float64(0.23555555555555557), 'gamma': 0, 'colsample_bytree': np.float64(0.8)}\n",
      "Best CV accuracy: 0.9090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\r\\Machine_Learning\\HRV Early cardiac risk detection\\.venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:18:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "# Define the XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Parameter grid for RandomizedSearch\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(50, 300, 50),\n",
    "    'max_depth': np.arange(3, 10),\n",
    "    'learning_rate': np.linspace(0.01, 0.3, 10),\n",
    "    'subsample': np.linspace(0.6, 1.0, 5),\n",
    "    'colsample_bytree': np.linspace(0.6, 1.0, 5),\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],\n",
    "    'reg_alpha': [0, 0.01, 0.1],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "# Randomized search with 5-fold stratified CV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit random search\n",
    "random_search.fit(X_scaled, y)\n",
    "\n",
    "print(\"Best parameters found:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "print(f\"Best CV accuracy: {random_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[18  2]\n",
      " [ 2 15]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        20\n",
      "           1       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.89        37\n",
      "   macro avg       0.89      0.89      0.89        37\n",
      "weighted avg       0.89      0.89      0.89        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Best params from RandomizedSearchCV (remove np types)\n",
    "best_params = {\n",
    "    'subsample': 0.8,\n",
    "    'reg_lambda': 2,\n",
    "    'reg_alpha': 0.1,\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.23555555555555557,\n",
    "    'gamma': 0,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': 42,\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "\n",
    "# Initialize model with best params\n",
    "best_xgb = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "# Train on training data\n",
    "best_xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = best_xgb.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
